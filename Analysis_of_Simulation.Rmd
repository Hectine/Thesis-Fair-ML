---
title: "Analysis of simulated data"
author: "Leona"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Overview of the markdown
The script is an R Markdown document for analyzing simulated data with a focus on evaluating fairness across different machine learning models and subpopulations. It includes steps for data preprocessing, model training, evaluation, and fairness assessment across various sensitive attributes like gender, disability, and ethnicity. The script can handle multiple machine learning algorithms, produce performance metrics, and assess fairness through confusion matrices and other statistical measures.

# Load dataset
```{r}
# set data
data <- simulated_data

# set necessary variables to factors
data[,2] <- as.factor(data[,2])
data[,3] <- as.factor(data[,3])
data[,6] <- as.factor(data[,6])
data[,7] <- as.factor(data[,7])
data[,9] <- as.factor(data[,9])
data[,11] <- as.factor(data[,11])

# set necessary variables to numeric
data[,10] <- as.numeric(data[,10])
```

# Load libraries
This block loads the necessary R libraries for data manipulation (tidyverse), machine learning algorithms (randomForest, e1071, xgboost, ada), and performance metrics (pROC).
```{r}
library(tidyverse)
library(randomForest)
library(pROC)
library(e1071)
library(xgboost)
library(ada)
library(mice)
library(missForest)
library(smotefamily)
library(ROSE)
```

# Analysis set-up
Initializes key parameters including the choice of algorithm, whether model hyperparameters are tuned, and the classification threshold.
```{r}
# 1. Model choice
# Select the algorithm for the analysis. Options include:
# - "linear_regression"
# - "logistic_regression"
# - "random_forest"
# - "svm"
# - "xgboost"
# - "adaboost"
algorithm <- "logistic_regression"

# Ensure the chosen algorithm is valid
valid_algorithms <- c("linear_regression", "logistic_regression", "random_forest", "svm", "xgboost", "adaboost")
if (!algorithm %in% valid_algorithms) {
  stop("Invalid algorithm chosen. Please select from the valid options: ", paste(valid_algorithms, collapse = ", "))
}

# 2. Tuned model
# Indicates whether the model's hyperparameters will be optimized.
# If set to TRUE, hyperparameter tuning methods will be applied.
tuned <- FALSE

# 3. Threshold setting
# Sets the decision boundary for classification.
# This is relevant for binary classification models.
threshold <- 0.5

# Validate that threshold is between 0 and 1
if (threshold < 0 || threshold > 1) {
  stop("Threshold must be between 0 and 1.")
}

# 4.1 Missing data handling
# Indicates whether the dataset contains missing data that needs to be addressed.
missing_data <- FALSE

# 4.2 Imputation method for missing data
# Choose an imputation method to handle missing values in the dataset. Options include:
# - "simple_value_imputation": Imputes using mean for numeric and mode for categorical variables.
# - "MICE_method": Multivariate Imputation by Chained Equations.
# - "Miss_Forest_Imputation": Imputation using Random Forests.
NA_method <- "simple_value_imputation"

# Ensure the chosen imputation method is valid
valid_imputation_methods <- c("simple_value_imputation", "MICE_method", "Miss_Forest_Imputation")
if (!NA_method %in% valid_imputation_methods) {
  stop("Invalid imputation method chosen. Please select from the valid options: ", paste(valid_imputation_methods, collapse = ", "))
}

# 5.1 Handling scarce outcome
# Indicate whether crime outcome is scarcely distributed in the dataset
scarce_outcome <- TRUE

# 5.2 Chose method to handle scarce outcome
# - "no_method"
# - "SMOTE_method"
# - "random_oversampling"
# - "random_undersampling"
scarce_outcome_method <- "random_undersampling"

# Print out the setup parameters to confirm choices
cat("Setup Parameters:\n")
cat("Algorithm:", algorithm, "\n")
cat("Tuned Model:", tuned, "\n")
cat("Threshold:", threshold, "\n")
cat("Missing Data:", missing_data, "\n")
cat("Imputation Method:", NA_method, "\n")
cat("Scarce outcome:", scarce_outcome)
```

# Missing data imputation
This code block is designed to handle missing data within a dataset by employing different imputation methods based on the user's selection. It dynamically identifies binary and numeric variables and then applies the appropriate imputation technique to each variable type. The three imputation methods included are simple value imputation, MICE (Multivariate Imputation by Chained Equations), and missForest. The code is adaptable to different datasets, as it identifies variable types automatically and handles missing data accordingly.
```{r}
# Identification of binary and numeric variables in the dataset
# Binary columns are those that are either factors or logicals
binary_columns <- which(sapply(data, function(x) is.factor(x) | is.logical(x)))
# Numeric columns are those identified as numeric data types
numeric_columns <- which(sapply(data, is.numeric))

if(missing_data == TRUE) {
  
  # 1. Simple Value Imputation
  if(NA_method == "simple_value_imputation") {
    # Imputation for binary columns
    for (col in binary_columns) {
      # Calculate the mode (most frequent value) for each binary column, ignoring NA values
      mode_value <- names(which.max(table(data[, col], useNA = "no")))
      # Replace missing values with the calculated mode
      data[, col][is.na(data[, col])] <- mode_value
    }
  
    # Imputation for numeric columns
    for (col in numeric_columns) {
      # Replace missing values with the mean of the column, ignoring NA values
      data[, col] <- replace(data[, col], is.na(data[, col]), mean(data[, col], na.rm = TRUE))
    }
  }
  
  # 2. MICE (Multivariate Imputation by Chained Equations) Method
  if(NA_method == "MICE_method") {
    # Iterate over columns from the 4th to the last column of the dataset
    for (col in 4:ncol(data)) {
      # Perform imputation using the MICE method with 'cart' (Classification and Regression Trees)
      # The 'm = 1' argument specifies that only one imputation dataset should be created
      data[, col] <- complete(mice(data, method = "cart", m = 1))[, col]
    }
  }
  
  # 3. Miss Forest Imputation Method
  if(NA_method == "Miss_Forest_Imputation") {
    # Perform missForest imputation on the entire dataset
    # missForest handles both continuous and categorical variables
    # The imputed dataset is returned and assigned back to the original data variable
    data <- missForest(data)$ximp
  }
}
```

# Old data imputation code
```{#r}
if(missing_data == TRUE) {
  
  if(NA_method == "mean_simple_value_imputation") {
    # replace missing education level with majority education level
    data[,4] <- replace(data[,4], is.na(data[,4]), names(which.max(table(data[,4]))))
    
    # replace with mean value
    data[,5] <- replace(data[,5], is.na(data[,5]), mean(data[,5], na.rm = TRUE))
    data[,8] <- replace(data[,8], is.na(data[,8]), mean(data[,8], na.rm = TRUE))
    data[,10] <- replace(data[,10], is.na(data[,10]), mean(data[,10], na.rm = TRUE))
    
    # replace with majority category
    data[,6][is.na(data[,6])] <- as.numeric(names(which.max(table(data[,6]))[1]))
    data[,7][is.na(data[,7])] <- as.numeric(names(which.max(table(data[,7]))[1]))
    data[,9][is.na(data[,9])] <- as.numeric(names(which.max(table(data[,9]))[1]))
    data[,11][is.na(data[,11])] <- as.numeric(names(which.max(table(data[,11]))[1]))
  }
  
  if(NA_method == "MICE_method") {
    # perform initial inspection of missing values
    md.pattern(data)
    
    # impute missing education levels
    data[,4] <- complete(mice(data[,1:4], method = "cart"))[,4]
    
    # impute missing values in other variables
    data[,5] <- complete(mice(data[,c(1:3, 5)], method = "cart"))[,4]
    data[,6] <- complete(mice(data[,c(1:3, 6)], method = "cart"))[,4]
    data[,7] <- as.numeric(data[,7])
    data[,7] <- complete(mice(data[,c(1:3, 7)], method = "cart"))[,4]
    data[,8] <- complete(mice(data[,c(1:3, 8)], method = "cart"))[,4]
    data[,9] <- as.factor(data[,9])
    data[,9] <- complete(mice(data[,c(1:3, 9)], method = "cart"))[,4]
    data[,10] <- as.numeric(data[,10])
    data[,10] <- complete(mice(data[,c(1:3, 10)], method = "cart"))[,4]
    data[,11] <- complete(mice(data[,c(1:3, 11)], method = "cart"))[,4]
  }
  
  if(NA_method == "Miss_Forest_Imputation") {
    # Perform missForest imputation on the entire dataset
    imputed_data <- missForest(data)$ximp
    
    # Extract the imputed columns
    data[,4] <- imputed_data[,4]
    data[,5] <- imputed_data[,5]
    data[,6] <- imputed_data[,6]
    data[,7] <- imputed_data[,7]
    data[,8] <- imputed_data[,8]
    data[,9] <- imputed_data[,9]
    data[,10] <- imputed_data[,10]
    data[,11] <- imputed_data[,11]
  }
}
```

# Train/Test split
Splits the data into training (80%) and testing (20%) sets to allow model training and performance evaluation. The split is randomized but reproducible due to the set seed.
```{r}
# set seed
set.seed(123)

# set proportion of train/test split
n <- nrow(data)
n_train <- round(n * 0.8)

# sample train indices
train_index <- sample(1:n, size = n_train)

# obtain train and test set
data_train <- data[train_index,]
data_test <- data[-train_index,]
```

# Scarce outcome intervention
This R code block is designed to address the issue of class imbalance in a dataset, specifically targeting the situation where one class (e.g., a crime outcome) is underrepresented (scarce outcome). It offers three different methods to handle the imbalance: random oversampling, SMOTE (Synthetic Minority Over-sampling Technique), and random undersampling. The code adjusts the training dataset accordingly based on the selected method.

1. Random over-sampling
    This method duplicates instances of the minority class until its size matches the         majority class, effectively balancing the dataset.
    
2. SMOTE (Synthetic Minority Over-sampling Technique)
    SMOTE generates synthetic instances of the minority class by interpolating between existing instances, thus increasing its representation in the dataset.
    
3. Random under-sampling
    This method reduces the size of the majority class by randomly selecting instances to match the minority class, creating a balanced dataset with fewer instances.
```{r}
if (scarce_outcome == TRUE) {
  
  # 1. Random oversampling of the minority class
  if (scarce_outcome_method == "random_oversampling") {
    
    # Calculate the new sample size for oversampling
    new_N <- table(data_train$crime)[1] * 2
    
    # Perform oversampling on the minority class to match the majority class size
    data_train = ovun.sample(crime ~ . , data = data_train, method = "over", N = new_N)$data
  }
  
  # 2. Oversampling the minority class using SMOTE
  if (scarce_outcome_method == "SMOTE_method") {

    # Identify non-numeric columns in the training data
    non_numeric_cols <- sapply(data_train, class) %in% c("factor", "character")

    # Convert non-numeric columns to one-hot encoded numeric columns
    if (any(non_numeric_cols)) {
      data_train_numeric <- model.matrix(~ . -1, data = data_train)
      data_train_numeric <- data.frame(data_train_numeric)

      # Ensure the target variable 'crime' is preserved and correct
      data_train_numeric$crime <- data_train$crime
    } else {
      data_train_numeric <- data_train
    }

    # Apply the SMOTE algorithm to generate synthetic samples for the minority class
    data_train_smote <- SMOTE(X = data_train_numeric[, -which(names(data_train_numeric) == "crime")],
                              target = data_train_numeric$crime,
                              K = 5,
                              dup_size = 0) 

    # Convert the SMOTE output back to a data frame
    data_train_smote <- data.frame(data_train_smote$data)
    data_train_smote$crime <- as.factor(ifelse(data_train_smote$crime == 1, 1, 0))

    # Revert the one-hot encoded variables back to their original categorical format
    data_train_smote$gender <- factor(ifelse(data_train_smote$genderFemale == 1, "Female", "Male"))
    data_train_smote$ethnicity <- factor(ifelse(data_train_smote$ethnicityMinority == 1, "Minority", "Non-Minority"))
    data_train_smote$disability <- factor(ifelse(data_train_smote$disabilityYes == 1, "Yes", "No"))

    # Handle missing values in the education variable and recombine levels
    education_levels <- c("No High School", "High School", "Some College", "Bachelor's", "Master's", "Doctorate")

    data_train_smote$education <- apply(data_train_smote[, c("educationHigh.School", "educationSome.College", 
                                                             "educationBachelor.s", "educationMaster.s", "educationDoctorate")], 1, 
                                        function(x) {
                                          if (all(x == 0)) {
                                            return("No High School")
                                          } else {
                                            return(education_levels[which(x == 1) + 1])
                                          }
                                        })

    # Convert to factor with all levels, even if some are missing in the SMOTE'd data
    data_train_smote$education <- factor(data_train_smote$education, levels = education_levels)

    # Remove the one-hot encoded columns as they are no longer needed
    data_train_smote <- data_train_smote[, !(names(data_train_smote) %in% 
                                             c("genderFemale", "genderMale", "ethnicityMinority", "disabilityYes", 
                                               "educationHigh.School", "educationSome.College", 
                                               "educationBachelor.s", "educationMaster.s", "educationDoctorate"))]

    # Fix column names to match the expected output format
    colnames(data_train_smote) <- gsub("new_var1", "new_var", colnames(data_train_smote))
    colnames(data_train_smote) <- gsub("new_var31", "new_var3", colnames(data_train_smote))
    colnames(data_train_smote)[colnames(data_train_smote) == "house_ownership1"] <- "house_ownership"
    colnames(data_train_smote)[colnames(data_train_smote) == "crime1"] <- "crime"

    # Remove any duplicate 'crime' columns that may have been created during processing
    data_train_smote <- data_train_smote[, !duplicated(names(data_train_smote))]

    # Reorder columns to match the original dataset's column order
    original_order <- c("gender", "ethnicity", "disability", "education", "income", "house_ownership", 
                        "new_var", "new_var2", "new_var3", "new_var4", "crime")
    data_train_smote <- data_train_smote[, original_order]
    
    # Ensure the data types match between training and testing datasets
    data_train_smote$crime <- factor(data_train_smote$crime, levels = c(0, 1))
    data_train_smote$house_ownership <- factor(data_train_smote$house_ownership, levels = c(0, 1))
    data_train_smote$new_var <- factor(data_train_smote$new_var, levels = c(0, 1))
    data_train_smote$new_var3 <- factor(data_train_smote$new_var3, levels = c(0, 1))

    # Update the training data with the SMOTE-processed data
    data_train <- data_train_smote
  }
  
  # 3. Random undersampling of the majority class
  if (scarce_outcome_method == "random_undersampling") {
    
    # Calculate the new sample size for undersampling
    new_N <- table(data_train$crime)[2] * 2
    
    # Perform undersampling on the majority class to match the minority class size
    data_train = ovun.sample(crime ~ . , data = data_train, method = "under", N = new_N)$data
  }
}
```

# Linear regression
Implements linear regression for predicting the probability of a crime. Linear regression models the relationship between the dependent variable (crime) and the independent variables (features) by fitting a linear equation to observed data.
```{r}
if(algorithm == "linear_regression"){
  # apply default linear regression
  model <- glm(crime ~ ., data = data_train[,4:11])
  
  # obtain predicted probabilities for the training data
  probabilities_train <- predict(model, newdata = data_train, type = "response")
  
  # obtain predicted probabilities for the test data
  probabilities_test <- predict(model, newdata = data_test, type = "response") 
}
```

# Logistic regression
Implements logistic regression to predict binary outcomes (crime or no crime). Logistic regression uses a logistic function to model the probability that a given input belongs to a certain class.
```{r}
if(algorithm == "logistic_regression"){
  
  # apply default logistic regression
  model <- glm(crime ~ ., data = data_train[,4:11], family = "binomial")
  
  # obtain predicted probabilities for the training data
  probabilities_train <- predict(model, newdata = data_train, type = "response")
  
  # obtain predicted probabilities for the test data
  probabilities_test <- predict(model, newdata = data_test, type = "response")
}
```

# Random Forest
Implements a random forest model, an ensemble learning method that builds multiple decision trees and merges them together to get a more accurate and stable prediction. It works by averaging the predictions from each tree.
```{r}
if(algorithm == "random_forest"){
  
  # apply default random forest
  model <- randomForest(as.factor(crime) ~ ., data = data_train[,4:11])
  
  # obtain predicted probabilities for the training data
  probabilities_train <- predict(model, newdata = data_train, type = "prob")[,2]
  
  # obtain predicted probabilities for the test data
  probabilities_test <- predict(model, newdata = data_test, type = "prob")[,2]
}
```

# Support vector machnine
Implements an SVM model, which classifies data by finding the hyperplane that best separates data into classes. The SVM uses a kernel function (like radial basis) to handle non-linear data. The script extracts the predicted probabilities of belonging to each class.
```{r}
if (algorithm == "svm") {

  # Fit the SVM model (using a radial basis kernel as default)
  model <- svm(as.factor(crime) ~ ., data = data_train[,4:11], probability = TRUE)
  
  # Obtain predicted probabilities for the training data
  probabilities_train <- attr(predict(model, newdata = data_train, probability = TRUE), "probabilities")[,1]
  
  # Obtain predicted probabilities for the test data
  probabilities_test <- attr(predict(model, newdata = data_test, probability = TRUE), "probabilities")[,1]
}
```

# XGboost
Implements XGBoost, a gradient boosting algorithm that builds an ensemble of decision trees iteratively, optimizing the model based on the errors of previous models. It’s known for high performance in predictive tasks.
```{r}
if (algorithm == "xgboost") {

  # Convert data to numeric matrix, converting factors/characters to numeric
  train_matrix <- data.matrix(data_train[, 4:10])
  test_matrix <- data.matrix(data_test[, 4:10])
  
  # Convert target variable to numeric and ensure it is binary (0 and 1)
  train_label <- as.numeric(as.factor(data_train$crime)) - 1 # Assumes 'crime' is a factor or character
  test_label <- as.numeric(as.factor(data_test$crime)) - 1
  
  # Ensure labels are binary (0 and 1)
  if (any(train_label < 0 | train_label > 1) || any(test_label < 0 | test_label > 1)) {
    stop("Labels must be binary (0 and 1).")
  }

  # Create DMatrix objects for XGBoost
  dtrain <- xgb.DMatrix(data = train_matrix, label = train_label)
  dtest <- xgb.DMatrix(data = test_matrix, label = test_label)
  
  # Set default parameters for XGBoost
  params <- list(
    objective = "binary:logistic",
    eval_metric = "logloss"
  )
  
  # Train the XGBoost model
  model <- xgboost(params = params, data = dtrain, nrounds = 100, verbose = 0)
  
  # Obtain predicted probabilities for the training data
  probabilities_train <- predict(model, dtrain)
  
  # Obtain predicted probabilities for the test data
  probabilities_test <- predict(model, dtest)
}
```

# Adaboost
Implements AdaBoost, a boosting algorithm that combines multiple weak learners (usually decision stumps) to create a strong classifier. It assigns more weight to incorrectly classified instances to focus learning on difficult cases.
```{r}
if (algorithm == "adaboost") {
  
  # Ensure the target variable is binary (0 and 1)
  train_label <- as.numeric(as.factor(data_train$crime)) - 1 # Assumes 'crime' is a factor or character
  test_label <- as.numeric(as.factor(data_test$crime)) - 1

  # Ensure labels are binary (0 and 1)
  if (any(train_label < 0 | train_label > 1) || any(test_label < 0 | test_label > 1)) {
    stop("Labels must be binary (0 and 1).")
  }
  
  # Prepare the training and test data
  train_data <- data_train[, 4:10]
  test_data <- data_test[, 4:10]
  
  # Fit the AdaBoost model
  model <- ada(x = train_data, y = train_label, iter = 50, nu = 0.1, type = "real")
  
  # Obtain predicted probabilities for the training data
  probabilities_train <- predict(model, newdata = train_data, type = "prob")[,2]
  
  # Obtain predicted probabilities for the test data
  probabilities_test <- predict(model, newdata = test_data, type = "prob")[,2]
}
```

# Obtain binary crime classification for test and training data
Converts the predicted probabilities into binary classifications based on the threshold. It then creates confusion matrices to compare the predictions against actual labels.
```{r}
  # convert training data probabilities into binary depending on threshold
  prediction_train <- ifelse(probabilities_train >= threshold, 1, 0)
  
  # convert test data probabilities into binary depending on threshold
  prediction_test <- ifelse(probabilities_test >= threshold, 1, 0)

  # confusion matrix of classification showing TP/FP and TN/FN for training data
  cm_train <- table(data_train$crime, prediction_train)
  
  # confusion matrix of classification showing TP/FP and TN/FN for test data
  cm_test <- table(data_test$crime, prediction_test)
```

# Inspect model efficiency (ROC & AUC)
Evaluates the model’s performance using metrics like ROC-AUC, which measures the trade-off between true positive and false positive rates, and accuracy, which measures the proportion of correct predictions.
```{r}
# obtain ROC
roc_curve <- roc(data_test$crime, prediction_test)

# obtain AUC
auc_value <- auc(roc_curve)

# Accuracy (training data)
accuracy_train <- (cm_train[1,1] + cm_train[2,2]) / sum(cm_train)

# Accuracy (test data)
accuracy_test <- (cm_test[1,1] + cm_test[2,2]) / sum(cm_test)

# print output
cat("### Model performance ###", "\nThe Area under the Curve is:", round(auc_value, 3), "\nAccuracy (training):",
    accuracy_train, "\nAccuracy (test):", accuracy_test)
```

# Generation of confusion matrix for single sensitive attribute comparisons (gender, disability, ethnicity)
Generates confusion matrices for different subpopulations based on gender, disability, and ethnicity, allowing for an assessment of how well the model performs across these groups.
```{r}
# 1. Gender comparison
# Index selection
indices_train_male <- which(data_train$gender == "Male")
indices_test_male <- which(data_test$gender == "Male")
indices_train_female <- which(data_train$gender == "Female")
indices_test_female <- which(data_test$gender == "Female")

# Confusion matrix
cm_train_male <- table(data_train[indices_train_male,]$crime, prediction_train[indices_train_male])
cm_train_female <- table(data_train[indices_train_female,]$crime, prediction_train[indices_train_female])
cm_test_male <- table(data_test[indices_test_male,]$crime, prediction_test[indices_test_male])
cm_test_female <- table(data_test[indices_test_female,]$crime, prediction_test[indices_test_female])

# 2. Disability comparison
# Index selection
indices_train_disabled <- which(data_train$disability == "Yes")
indices_test_disabled <- which(data_test$disability == "Yes")
indices_train_abled <- which(data_train$disability == "No")
indices_test_abled <- which(data_test$disability == "No")

# Confusion matrix
cm_train_disabled <- table(data_train[indices_train_disabled,]$crime, prediction_train[indices_train_disabled])
cm_train_abled <- table(data_train[indices_train_abled,]$crime, prediction_train[indices_train_abled])
cm_test_disabled <- table(data_test[indices_test_disabled,]$crime, prediction_test[indices_test_disabled])
cm_test_abled <- table(data_test[indices_test_abled,]$crime, prediction_test[indices_test_abled])

# 3. Ethnicity comparison
# Index selection
indices_train_minority <- which(data_train$ethnicity == "Minority")
indices_test_minority <- which(data_test$ethnicity == "Minority")
indices_train_majority <- which(data_train$ethnicity == "Majority")
indices_test_majority <- which(data_test$ethnicity == "Majority")

# Confusion matrix
cm_train_minority <- table(data_train[indices_train_minority,]$crime, prediction_train[indices_train_minority])
cm_train_majority <- table(data_train[indices_train_majority,]$crime, prediction_train[indices_train_majority])
cm_test_minority <- table(data_test[indices_test_minority,]$crime, prediction_test[indices_test_minority])
cm_test_majority <- table(data_test[indices_test_majority,]$crime, prediction_test[indices_test_majority])
```

# Benchmark metric
Computes benchmark fairness metrics, including demographic parity (proportion of favorable outcomes), false positive rate (FPR), and false negative rate (FNR) for both training and test data.
```{r}
# Calculate Benchmark metrics for training data
proportion_favorable_benchmark_train <- sum(cm_train[,1]) / sum(cm_train)
FPR_benchmark_train <- cm_train[1,2] / (cm_train[1,2] + cm_train[1,1])
FNR_benchmark_train <- cm_train[2,1] / (cm_train[2,1] + cm_train[2,2])

# Calculate Benchmark metrics for test data
proportion_favorable_benchmark_test <- sum(cm_test[,1]) / sum(cm_test)
FPR_benchmark_test <- cm_test[1,2] / (cm_test[1,2] + cm_test[1,1])
FNR_benchmark_test <- cm_test[2,1] / (cm_test[2,1] + cm_test[2,2])

# Output
cat("### Benchmark fairness measures ###\n\n1.Training Data\n- Demographic Parity:",
    round(proportion_favorable_benchmark_train,3),
    "\n- FPR:", round(FPR_benchmark_train,3), "\n- FNR:", round(FNR_benchmark_train,3),
    "\n\n2.Test Data\n- Demographic Parity:",
    round(proportion_favorable_benchmark_test,3), "\n- FPR:", 
    round(FPR_benchmark_test,3), "\n- FNR:", round(FNR_benchmark_test,3))
```

# Function to calculate fairness metrics 
This R function, calculate_metrics, is designed to compute fairness metrics from a confusion matrix. It calculates key fairness metrics such as the proportion of favorable outcomes (Demographic Parity), False Positive Rate (FPR), and False Negative Rate (FNR) for a given model. The function also compares these metrics against a benchmark confusion matrix to provide ratios that indicate how the model's performance compares to the benchmark in terms of fairness.
```{r}
# Function to calculate fairness metrics for a given confusion matrix
calculate_metrics <- function(cm, cm_benchmark) {
  # Initialize variables for metrics
  proportion_favorable <- NA
  FPR <- NA
  FNR <- NA
  
  # Check if the confusion matrix has the expected dimensions (2x2)
  if (all(dim(cm) == c(2, 2))) {
    # Calculate Proportion of Favorable Outcome (Demographic Parity)
    proportion_favorable <- sum(cm[,1]) / sum(cm)
    
    # Calculate False Positive Rate (FPR)
    if ((cm[1,2] + cm[1,1]) > 0) {
      FPR <- cm[1,2] / (cm[1,2] + cm[1,1])
    }
    
    # Calculate False Negative Rate (FNR)
    if ((cm[2,1] + cm[2,2]) > 0) {
      FNR <- cm[2,1] / (cm[2,1] + cm[2,2])
    }
  }
  
  # Calculate Benchmark metrics
  proportion_favorable_benchmark <- sum(cm_benchmark[,1]) / sum(cm_benchmark)
  FPR_benchmark <- cm_benchmark[1,2] / (cm_benchmark[1,2] + cm_benchmark[1,1])
  FNR_benchmark <- cm_benchmark[2,1] / (cm_benchmark[2,1] + cm_benchmark[2,2])

  # Calculate ratios relative to the benchmark
  proportion_favorable_ratio <- if (!is.na(proportion_favorable)) proportion_favorable / proportion_favorable_benchmark else NA
  FPR_ratio <- if (!is.na(FPR)) FPR / FPR_benchmark else NA
  FNR_ratio <- if (!is.na(FNR)) FNR / FNR_benchmark else NA
  
  return(list(proportion_favorable = proportion_favorable, proportion_favorable_ratio = proportion_favorable_ratio, 
              FPR = FPR, FPR_ratio = FPR_ratio, 
              FNR = FNR, FNR_ratio = FNR_ratio))
}
```

# Calculation and display of the three fairness metrics for single senstive attribute comparisons
This code block performs a detailed comparison of fairness metrics across different sensitive attributes (such as gender, disability status, and ethnicity) by calculating and displaying key metrics like Proportion of Favorable Outcome (Demographic Parity), False Positive Rate (FPR), and False Negative Rate (FNR). These metrics are calculated separately for both training and testing datasets, and results are compared against a benchmark to assess fairness.

1. Comparative Fairness Analysis: The code performs a detailed comparative analysis of fairness across different sensitive groups, making it possible to identify biases in model predictions.

2. Benchmarking: By comparing subgroup metrics against overall benchmarks, the code provides context for understanding disparities in model performance.
```{r}
# Function to display the results in a structured format
display_results <- function(subpop, metrics_train, metrics_test) {
  cat("### Results for:", subpop, "###\n")
  
  cat("Training Data:\n")
  cat("1. Proportion of Favorable Outcome (Demographic Parity):", metrics_train$proportion_favorable, 
      "(Ratio to Benchmark:", metrics_train$proportion_favorable_ratio, ")\n")
  cat("2. False Positive Rate (FPR):", metrics_train$FPR, 
      "(Ratio to Benchmark:", metrics_train$FPR_ratio, ")\n")
  cat("3. False Negative Rate (FNR):", metrics_train$FNR, 
      "(Ratio to Benchmark:", metrics_train$FNR_ratio, ")\n\n")
  
  cat("Test Data:\n")
  cat("1. Proportion of Favorable Outcome (Demographic Parity):", metrics_test$proportion_favorable, 
      "(Ratio to Benchmark:", metrics_test$proportion_favorable_ratio, ")\n")
  cat("2. False Positive Rate (FPR):", metrics_test$FPR, 
      "(Ratio to Benchmark:", metrics_test$FPR_ratio, ")\n")
  cat("3. False Negative Rate (FNR):", metrics_test$FNR, 
      "(Ratio to Benchmark:", metrics_test$FNR_ratio, ")\n\n")
}

# Calculate benchmark metrics
cm_train <- table(data_train$crime, prediction_train)
cm_test <- table(data_test$crime, prediction_test)

# Gender comparison
metrics_train_male <- calculate_metrics(cm_train_male, cm_train)
metrics_test_male <- calculate_metrics(cm_test_male, cm_test)

metrics_train_female <- calculate_metrics(cm_train_female, cm_train)
metrics_test_female <- calculate_metrics(cm_test_female, cm_test)

# Display results for gender comparison
display_results("Male", metrics_train_male, metrics_test_male)
display_results("Female", metrics_train_female, metrics_test_female)

# Disability comparison
metrics_train_disabled <- calculate_metrics(cm_train_disabled, cm_train)
metrics_test_disabled <- calculate_metrics(cm_test_disabled, cm_test)

metrics_train_abled <- calculate_metrics(cm_train_abled, cm_train)
metrics_test_abled <- calculate_metrics(cm_test_abled, cm_test)

# Display results for disability comparison
display_results("Disabled", metrics_train_disabled, metrics_test_disabled)
display_results("Non-Disabled", metrics_train_abled, metrics_test_abled)

# Ethnicity comparison
metrics_train_minority <- calculate_metrics(cm_train_minority, cm_train)
metrics_test_minority <- calculate_metrics(cm_test_minority, cm_test)

metrics_train_majority <- calculate_metrics(cm_train_majority, cm_train)
metrics_test_majority <- calculate_metrics(cm_test_majority, cm_test)

# Display results for ethnicity comparison
display_results("Minority", metrics_train_minority, metrics_test_minority)
display_results("Majority", metrics_train_majority, metrics_test_majority)
```

# Function to find most advantages and disadvantaged subpopulations 
This code block defines a function find_extremes that identifies the most privileged and most disadvantaged subpopulations based on three fairness metrics: False Positive Rate (FPR), False Negative Rate (FNR), and Proportion of Favorable Outcome (Demographic Parity). The function takes in a list of calculated metrics for various subpopulations and returns the subpopulation names that exhibit the most extreme values—either advantageous or disadvantageous—across these metrics.
```{r}
# Function to find the most privileged and most disadvantaged subpopulations
find_extremes <- function(metrics_list) {
  most_privileged <- list(FPR = NULL, FNR = NULL, Demographic_Parity = NULL)
  most_disadvantaged <- list(FPR = NULL, FNR = NULL, Demographic_Parity = NULL)
  
  min_FPR <- min(sapply(metrics_list, function(x) x$FPR), na.rm = TRUE)
  max_FNR <- max(sapply(metrics_list, function(x) x$FNR), na.rm = TRUE)
  max_DP <- max(sapply(metrics_list, function(x) x$proportion_favorable), na.rm = TRUE)
  
  max_FPR <- max(sapply(metrics_list, function(x) x$FPR), na.rm = TRUE)
  min_FNR <- min(sapply(metrics_list, function(x) x$FNR), na.rm = TRUE)
  min_DP <- min(sapply(metrics_list, function(x) x$proportion_favorable), na.rm = TRUE)
  
  for (subpop in names(metrics_list)) {
    metrics <- metrics_list[[subpop]]
    
    # Safely compare metrics, only if they are not NA
    if (!is.na(metrics$FPR) && metrics$FPR == min_FPR) most_privileged$FPR <- subpop
    if (!is.na(metrics$FNR) && metrics$FNR == max_FNR) most_privileged$FNR <- subpop
    if (!is.na(metrics$proportion_favorable) && metrics$proportion_favorable == max_DP) most_privileged$Demographic_Parity <- subpop
    
    if (!is.na(metrics$FPR) && metrics$FPR == max_FPR) most_disadvantaged$FPR <- subpop
    if (!is.na(metrics$FNR) && metrics$FNR == min_FNR) most_disadvantaged$FNR <- subpop
    if (!is.na(metrics$proportion_favorable) && metrics$proportion_favorable == min_DP) most_disadvantaged$Demographic_Parity <- subpop
  }
  
  return(list(most_privileged = most_privileged, most_disadvantaged = most_disadvantaged))
}
```

# Assessment of fairness metrics on fine-grained subpopulations
This code block performs an assessment of fairness metrics across fine-grained subpopulations defined by combinations of gender, ethnicity, and disability status. It evaluates the model's performance on these subpopulations, identifying which groups are the most advantaged and disadvantaged based on various fairness metrics. The process involves calculating and displaying the metrics for each subpopulation, and then ranking them to determine which subpopulations are the most privileged and the most disadvantaged.

1. Fine-Grained Fairness Analysis: By breaking down the dataset into small subpopulations based on multiple sensitive attributes, the code allows for a nuanced analysis of fairness.

2. Benchmarking and Comparison: The use of overall confusion matrices as benchmarks enables the assessment of relative fairness across different groups.

3. Identification of Extremes: The code helps identify the extremes in model performance, making it easier to target interventions or adjustments to improve fairness.

4. Comprehensive Coverage: The approach covers all possible combinations of gender, ethnicity, and disability, ensuring no group is overlooked in the fairness assessment.
```{r}
# Calculate benchmark metrics
cm_train <- table(data_train$crime, prediction_train)
cm_test <- table(data_test$crime, prediction_test)

# Create a list to store metrics for all subpopulations
subpop_metrics_train <- list()
subpop_metrics_test <- list()

# Iterate over combinations of Gender, Ethnicity, and Disability
for (gender in c("Male", "Female")) {
  for (ethnicity in c("Minority", "Majority")) {
    for (disability in c("Yes", "No")) {
      subpop <- paste(gender, ethnicity, disability, sep = "_")
      
      # Index selection
      indices_train <- which(data_train$gender == gender & data_train$ethnicity == ethnicity & data_train$disability == disability)
      indices_test <- which(data_test$gender == gender & data_test$ethnicity == ethnicity & data_test$disability == disability)
      
      # Confusion matrix
      cm_train_subpop <- table(data_train[indices_train,]$crime, prediction_train[indices_train])
      cm_test_subpop <- table(data_test[indices_test,]$crime, prediction_test[indices_test])
      
      # Calculate metrics
      metrics_train <- calculate_metrics(cm_train_subpop, cm_train)
      metrics_test <- calculate_metrics(cm_test_subpop, cm_test)
      
      # Store metrics
      subpop_metrics_train[[subpop]] <- metrics_train
      subpop_metrics_test[[subpop]] <- metrics_test
      
      # Display results
      display_results(subpop, metrics_train, metrics_test)
    }
  }
}

# Find the most privileged and most disadvantaged subpopulations
extremes_train <- find_extremes(subpop_metrics_train)
extremes_test <- find_extremes(subpop_metrics_test)

# Display the most privileged and disadvantaged subpopulations
cat("### RANKING OF SUBPOPULATIONS###")

cat("\n### Most Privileged Subpopulations (Training Data) ###\n")
cat("1. Lowest FPR:", extremes_train$most_privileged$FPR, "\n")
cat("2. Highest FNR (most desirable):", extremes_train$most_privileged$FNR, "\n")
cat("3. Highest Proportion of Favorable Outcome (Demographic Parity):", extremes_train$most_privileged$Demographic_Parity, "\n")

cat("\n### Most Disadvantaged Subpopulations (Training Data) ###\n")
cat("1. Highest FPR:", extremes_train$most_disadvantaged$FPR, "\n")
cat("2. Lowest FNR (least desirable):", extremes_train$most_disadvantaged$FNR, "\n")
cat("3. Lowest Proportion of Favorable Outcome (Demographic Parity):", extremes_train$most_disadvantaged$Demographic_Parity, "\n")

cat("\n### Most Privileged Subpopulations (Test Data) ###\n")
cat("1. Lowest FPR:", extremes_test$most_privileged$FPR, "\n")
cat("2. Highest FNR (most desirable):", extremes_test$most_privileged$FNR, "\n")
cat("3. Highest Proportion of Favorable Outcome (Demographic Parity):", extremes_test$most_privileged$Demographic_Parity, "\n")

cat("\n### Most Disadvantaged Subpopulations (Test Data) ###\n")
cat("1. Highest FPR:", extremes_test$most_disadvantaged$FPR, "\n")
cat("2. Lowest FNR (least desirable):", extremes_test$most_disadvantaged$FNR, "\n")
cat("3. Lowest Proportion of Favorable Outcome (Demographic Parity):", extremes_test$most_disadvantaged$Demographic_Parity, "\n")
```

